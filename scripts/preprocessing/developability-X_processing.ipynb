{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Matteo Pariset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Useful for Pylance\n",
    "from utils import *\n",
    "\n",
    "import utils\n",
    "utils.refresh(sys.modules[__name__])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert 'developability-X' raw files into dataset\n",
    "version 0.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PARAMs: Put the names (not the paths) of the files containing the DPs (chain vs structural respectively)\n",
    "chain_params_filename = \"AbChain_whole_mAbs_developability_final.csv\"\n",
    "struct_params_filename = \"AbStruc_whole_mAbs_developability_final.csv\"\n",
    "########################\n",
    "\n",
    "# The name of the processed dataset (suggested: developability-thera)\n",
    "dataset_name = \"developability-thera\"\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_dset = pd.read_csv(os.path.join(get_dataset_dir(dataset_name), chain_params_filename))\n",
    "struct_dset = pd.read_csv(os.path.join(get_dataset_dir(dataset_name), struct_params_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize columns\n",
    "cols_subst = {'identity_species': 'species', 'corrected_isotype': 'isotype'}\n",
    "for k,v in cols_subst.items():\n",
    "    chain_dset.rename({k: v}, axis=1, inplace=True);\n",
    "    struct_dset.rename({k: v}, axis=1, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care of missing columns\n",
    "\n",
    "if 'isotype' not in chain_dset.columns:\n",
    "    chain_dset['isotype'] = \"\"\n",
    "\n",
    "if 'rowid' not in chain_dset.columns:\n",
    "    chain_dset = chain_dset.reset_index()\n",
    "    chain_dset.rename({'index': 'rowid'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_dset = chain_dset.infer_objects()\n",
    "chain_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Sequences in Chain & Struct files coincide\n",
    "assert (chain_dset['aaSeqAbChain'] == struct_dset['aaSeqAbChain']).all(), \"Sequence mismatch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chunks_names = ['aaSeqFR1', 'aaSeqCDR1', 'aaSeqFR2', 'aaSeqCDR2', 'aaSeqFR3', 'aaSeqCDR3', 'aaSeqFR4']\n",
    "cdr_names = seq_chunks_names[1::2]\n",
    "fr_names = seq_chunks_names[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: CDRs+FRs decompose each sequence\n",
    "assert (chain_dset['aaSeqAbChain'] == chain_dset[seq_chunks_names].fillna(\"\").apply(\"\".join, axis=1)).all(), \"Cannot decompose sequence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_sequences = chain_dset['aaSeqAbChain'].value_counts()\n",
    "unq_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_seqs = unq_sequences.index[unq_sequences > 1].values\n",
    "repeated_seqs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_dev = chain_dset.query('aaSeqAbChain in @repeated_seqs')\n",
    "repeated_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_metrics = repeated_dev[['aaSeqAbChain'] + list(repeated_dev.columns.values[repeated_dev.columns.str.match(r\"Ab(Chain|Struc)\")])].groupby('aaSeqAbChain').agg(['mean', 'var'])\n",
    "repeated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Verify that max metric variance among metrics calculated for the same sequence is 0\n",
    "assert np.isclose(repeated_metrics[repeated_metrics.columns[repeated_metrics.columns.get_level_values(1) == \"var\"]].max().max(), 0), \"Metrics computed for the same sequence vary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute position and length of CDR & FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_idxs = (chain_dset.apply(lambda x: [x['aaSeqAbChain'].find(x[chunk_name]) for chunk_name in cdr_names], axis=1, result_type='expand')\n",
    "                      .rename({i: cdr + \"_idx\" for i, cdr in enumerate(cdr_names)}, axis=1))\n",
    "cdr_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_lengths = chain_dset[cdr_names].applymap(len).rename({cdr: cdr + \"_length\" for cdr in cdr_names}, axis=1)\n",
    "cdr_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect info on Ab origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_dset[['chain', 'species']].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_dset['isotype'].hist(bins=chain_dset['isotype'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VJ genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fraction of nan values:\")\n",
    "chain_dset['v_gene'].isna().mean(), chain_dset['j_gene'].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert (chain_dset['v_gene'].dropna() == struct_dset['v_gene'].dropna()).all(), f\"{(chain_dset['v_gene'].dropna() != struct_dset['v_gene'].dropna()).mean()}% of entries differ!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert (chain_dset['j_gene'].dropna() == struct_dset['j_gene'].dropna()).all(), f\"{(chain_dset['j_gene'].dropna() != struct_dset['j_gene'].dropna()).mean()}% of entries differ!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dset = chain_dset[['chain', 'species', 'isotype', 'v_gene', 'j_gene']].rename(\"AbOrig_\".__add__, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_regexp = re.compile(r\".*IG..[0-9]+\")\n",
    "orig_dset['AbOrig_v_gene_prefix'] = orig_dset['AbOrig_v_gene'].dropna().astype(str).apply(lambda x: ontology_regexp.match(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose curated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse clinical trial phase\n",
    "if \"highest_clin_trial\" in chain_dset.columns:\n",
    "    print(chain_dset['highest_clin_trial'].unique())\n",
    "\n",
    "    clin_trial_conversion = {\n",
    "        'Approved': 4,\n",
    "        'Phase-III': 3,\n",
    "        'Phase-II': 2,\n",
    "        'Phase-I': 1,\n",
    "        'Preregistration': 0,\n",
    "        'Phase-I/II': 1,\n",
    "        'Phase-II/III': 2,\n",
    "        'Preregistration (w)': 0,\n",
    "        'Approved (w)': 4,\n",
    "        'Preclinical': 0,\n",
    "        'Unknown': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_dset = chain_dset[['rowid', 'aaSeqAbChain', 'chain']].join(\n",
    "    [\n",
    "        cdr_idxs,\n",
    "        cdr_lengths,\n",
    "        # Orig info\n",
    "        orig_dset,\n",
    "        # Chain-based metrics\n",
    "        chain_dset.loc[:,chain_dset.columns.str.startswith(\"AbChain\")],\n",
    "        # Struct-based metrics\n",
    "        struct_dset.loc[:,struct_dset.columns.str.startswith(\"AbStruc\")]\n",
    "    ]\n",
    ")\n",
    "\n",
    "if \"highest_clin_trial\" in chain_dset.columns:\n",
    "    curated_dset = curated_dset.join(chain_dset['highest_clin_trial'].apply(clin_trial_conversion.get))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_dset['source_datasets'] = dataset_name\n",
    "\n",
    "# Column renaming & type enforcement\n",
    "curated_dset = curated_dset.rename({'aaSeqAbChain': 'sequence', 'chain': 'chain_type'}, axis=1)\n",
    "curated_dset['rowid'] = curated_dset['rowid'].astype(int)\n",
    "# Harmonize chain types\n",
    "curated_dset['chain_type'] = curated_dset['chain_type'].apply(lambda x: x.split(\"_\")[0] if x.find(\"_\") > -1 else x)\n",
    "curated_dset['AbOrig_chain'] = curated_dset['AbOrig_chain'].apply(lambda x: x.split(\"_\")[0] if x.find(\"_\") > -1 else x)\n",
    "curated_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_dset.to_csv(os.path.join(get_dataset_dir(dataset_name), f\"{dataset_name}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform metrics into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mdws = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mdws:\n",
    "    # use MWDS\n",
    "    selected_metrics = pd.read_csv(\"./reproducibility/extended_mwds_metrics.csv\").loc[:,'0'].to_numpy()\n",
    "    selected_metrics = np.intersect1d(selected_metrics, curated_dset.columns)\n",
    "    metrics_embs_name = \"mwds\"\n",
    "else:\n",
    "    # Select all metrics\n",
    "    selected_metrics = curated_dset.columns.str.contains(r\"(AbChain|AbStruc)\")\n",
    "    metrics_embs_name = \"metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = curated_dset.loc[:,selected_metrics]\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform comparisons of DP embedding across dataset, the list of metrics used should be the one used for native Abs\n",
    "native_dset = pd.read_csv(\"./reproducibility/developability_processed_{metrics_embs_name}.csv\")\n",
    "\n",
    "metrics_without_nans = native_dset.loc[:,native_dset.columns.str.contains(r\"(AbChain|AbStruc)\")].columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load std & mean from native Abs (since the same PCA will be used on this dataset too)\n",
    "native_labels = pd.read_csv(os.path.join(get_dataset_dir(\"developability\"), \"developability.csv\")).loc[:,metrics_without_nans]\n",
    "\n",
    "native_means = native_labels.mean()\n",
    "native_stds = native_labels.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "native_labels['AbStruc_weak_hbonds'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = metrics_df - native_means\n",
    "assert np.isclose(metrics_df.std() , 0).sum() == 0, \"Some metrics have zero variance, remove them\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove metrics not in original DP\n",
    "metrics_df = metrics_df.loc[:,metrics_without_nans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{metrics_df.isna().sum().sum()} nan entries remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill residual NaNs with the mean computed on the native Abs dataset\n",
    "for m_name in metrics_df.columns:\n",
    "    metrics_df[m_name] = metrics_df[m_name].fillna(native_dset[m_name].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert metrics_df.isna().sum().sum() == 0, \"NaNs entries left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df /= native_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_metric = metrics_df.columns[0]\n",
    "native_labels[distr_metric].hist(label=\"native\")\n",
    "chain_dset[distr_metric].hist(label=\"thera\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(f\"{distr_metric} comparison\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.std().plot.line()\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics with high (>= 10) residual stds:\")\n",
    "metrics_df.std()[metrics_df.std() >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_support = metrics_df.apply(lambda x: (x.min(), x.max()))\n",
    "metrics_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_metrics_support(metrics_df):\n",
    "    metrics_support = metrics_df.apply(lambda x: (x.min(), x.max()))\n",
    "    supp_fig, supp_ax = plt.subplots()\n",
    "    supp_ax.barh(range(metrics_df.columns.shape[0]), metrics_support.loc[0,:].values)\n",
    "    supp_ax.barh(range(metrics_df.columns.shape[0]), metrics_support.loc[1,:].values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_support(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aberration_threshold = 15\n",
    "aberrant_metrics = (metrics_support.abs() > aberration_threshold).sum(axis=0) > 0\n",
    "aberrant_metrics.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip aberrant values\n",
    "metrics_df = np.clip(metrics_df, -aberration_threshold, aberration_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_metrics_support(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics_df.std(), 'x');\n",
    "plt.xticks(rotation=90);\n",
    "plt.title(f\"Metrics stds for {dataset_name}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed metrics, for later inspection\n",
    "curated_metrics_dset = curated_dset[['sequence']].join(metrics_df)\n",
    "curated_metrics_dset.to_csv(f\"./reproducibility/{dataset_name}_processed_{metrics_embs_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "np.save(os.path.join(get_dataset_dir(dataset_name), f\"{dataset_name}_{metrics_embs_name}_seq.npy\"), metrics_df.values)\n",
    "\n",
    "# ... also by chain type\n",
    "metrics_embeddings_filename_template = dataset_name + \"_%s_%s_seq\"\n",
    "np.save(os.path.join(get_dataset_dir(dataset_name), metrics_embeddings_filename_template % (\"heavy\", metrics_embs_name)), metrics_df.loc[curated_dset['chain_type'] == \"heavy\"].values)\n",
    "np.save(os.path.join(get_dataset_dir(dataset_name), metrics_embeddings_filename_template % (\"light\", metrics_embs_name)), metrics_df.loc[curated_dset['chain_type'] == \"light\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform AA counts into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_one_hot(i):\n",
    "    ohe = np.zeros(20)\n",
    "    ohe[i] = 1\n",
    "    return ohe\n",
    "\n",
    "aa_list = sorted(['A','R','F','N','D','C','E','Q','G','H','I','L','K','M','P','S','T','W','Y','V'])\n",
    "aa_dict = dict([(x,_to_one_hot(i)) for i,x in enumerate(aa_list)])\n",
    "\n",
    "def aa_freq_embedding(dataframe, seq_column):\n",
    "    aa_count_array = np.vstack(dataframe[seq_column].apply(lambda x: np.array(reduce(lambda a, b: a+b, map(aa_dict.get, list(x))))))\n",
    "    aa_freq_array = aa_count_array/aa_count_array.sum(axis=1,keepdims=True)\n",
    "    return aa_freq_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_aa_freqs = aa_freq_embedding(curated_dset, \"sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(aa_list, curated_aa_freqs.mean(axis=0));\n",
    "plt.title(\"Fraction of AAs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "np.save(os.path.join(get_dataset_dir(dataset_name), f\"{dataset_name}_aas_seq.npy\"), curated_aa_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('adaptyv-dl-light': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f38bb75025c4d2f69c5d0a5942b16057928e7329d9b05d27d6b85c0d970840f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
